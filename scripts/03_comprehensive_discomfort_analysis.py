#!/usr/bin/env python3
"""
ë¬´ì‹¬ì²œ ì¢…í•© ë¶ˆì¾Œì§€ìˆ˜ ë¶„ì„
- 10ê°œ ë¶ˆì¾Œì§€ìˆ˜ ê³„ì‚° ë° ì„±ëŠ¥ ë¹„êµ
- ì‹œëŒ€ë³„ ê°œë°œ ìˆœì„œ vs ìˆ˜ìœ„ ì˜ˆì¸¡ ì„±ëŠ¥ ë¶„ì„
- ë³µì¡ë„ vs ì„±ëŠ¥ ê´€ê³„ ë¶„ì„
"""

import pandas as pd
import numpy as np
import warnings
from datetime import datetime
import json
import os

warnings.filterwarnings('ignore')

class ComprehensiveDiscomfortAnalyzer:
    """ì¢…í•© ë¶ˆì¾Œì§€ìˆ˜ ë¶„ì„ê¸°"""
    
    # ê° ë¶ˆì¾Œì§€ìˆ˜ì˜ ë©”íƒ€ë°ì´í„°
    INDEX_METADATA = {
        'effective_temperature': {
            'name': 'Effective Temperature',
            'development_year': 1923,
            'complexity': 'Simple',
            'formula_complexity_score': 1,
            'primary_use': 'Early comfort assessment',
            'variables_used': ['temperature', 'humidity'],
            'era': 'Early (1920s)'
        },
        'THI': {
            'name': 'Temperature-Humidity Index',
            'development_year': 1950,
            'complexity': 'Simple',
            'formula_complexity_score': 1,
            'primary_use': 'General comfort assessment',
            'variables_used': ['temperature', 'humidity'],
            'era': 'Classical (1950s)'
        },
        'traditional_DI': {
            'name': 'Traditional Discomfort Index',
            'development_year': 1950,
            'complexity': 'Simple', 
            'formula_complexity_score': 1,
            'primary_use': 'Basic thermal comfort',
            'variables_used': ['temperature', 'humidity'],
            'era': 'Classical (1950s)'
        },
        'WBGT_simple': {
            'name': 'Wet Bulb Globe Temperature (Simplified)',
            'development_year': 1956,
            'complexity': 'Moderate',
            'formula_complexity_score': 2,
            'primary_use': 'Military and sports safety',
            'variables_used': ['temperature', 'humidity'],
            'era': 'Classical (1950s)'
        },
        'humidex': {
            'name': 'Humidity Index (Canadian)',
            'development_year': 1965,
            'complexity': 'Moderate',
            'formula_complexity_score': 2,
            'primary_use': 'Canadian weather forecasting',
            'variables_used': ['temperature', 'humidity'],
            'era': 'Modern (1960s-1980s)'
        },
        'heat_index': {
            'name': 'Heat Index (Apparent Temperature)',
            'development_year': 1979,
            'complexity': 'Complex',
            'formula_complexity_score': 4,
            'primary_use': 'US weather forecasting',
            'variables_used': ['temperature', 'humidity'],
            'era': 'Modern (1960s-1980s)'
        },
        'apparent_temp': {
            'name': 'Apparent Temperature (Australian)',
            'development_year': 1984,
            'complexity': 'Moderate',
            'formula_complexity_score': 3,
            'primary_use': 'Australian weather services',
            'variables_used': ['temperature', 'humidity', 'wind_speed'],
            'era': 'Modern (1960s-1980s)'
        },
        'feels_like_temp': {
            'name': 'Feels Like Temperature',
            'development_year': 1990,
            'complexity': 'Moderate',
            'formula_complexity_score': 3,
            'primary_use': 'Modern weather apps',
            'variables_used': ['temperature', 'humidity', 'wind_speed'],
            'era': 'Contemporary (1990s-2010s)'
        },
        'UTCI_simplified': {
            'name': 'Universal Thermal Climate Index (Simplified)',
            'development_year': 2012,
            'complexity': 'Very Complex',
            'formula_complexity_score': 5,
            'primary_use': 'International climate assessment',
            'variables_used': ['temperature', 'humidity', 'wind_speed'],
            'era': 'Contemporary (1990s-2010s)'
        },
        'temp_humidity_composite': {
            'name': 'Temperature-Humidity Composite',
            'development_year': 2024,
            'complexity': 'Simple',
            'formula_complexity_score': 1,
            'primary_use': 'Water level prediction research',
            'variables_used': ['temperature', 'humidity'],
            'era': 'Latest (2020s)'
        }
    }
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.data_paths = {
            'cheongju_raw': '../../ì²­ì£¼ê¸ˆì²œ_ê¸°ìƒìˆ˜ìœ„_í†µí•©_2014_2023.csv',
            'gadeok_raw': '../../ê°€ë•_ê¸°ìƒìˆ˜ìœ„_í†µí•©_2014_2023.csv'
        }
        self.results = {}
    
    def calculate_effective_temperature(self, temp, humidity):
        """ìœ íš¨ì˜¨ë„ - ì´ˆê¸° ì—´í™˜ê²½ ì§€í‘œ (1923ë…„)"""
        try:
            return temp - (100 - humidity) / 4
        except:
            return np.nan
    
    def calculate_THI(self, temp, humidity):
        """Temperature-Humidity Index (1950ë…„)"""
        try:
            return (1.8 * temp + 32) - ((0.55 - 0.0055 * humidity) * (1.8 * temp - 26))
        except:
            return np.nan
    
    def calculate_traditional_DI(self, temp, humidity):
        """ì „í†µì  ë¶ˆì¾Œì§€ìˆ˜ (1950ë…„)"""
        try:
            return temp + 0.36 * humidity
        except:
            return np.nan
    
    def calculate_WBGT_simple(self, temp, humidity):
        """WBGT ê°„ì†Œí™” ê³µì‹ (1956ë…„)"""
        try:
            # ìŠµêµ¬ì˜¨ë„ ê·¼ì‚¬ ê³„ì‚°
            wet_bulb = temp * np.arctan(0.151977 * np.sqrt(humidity + 8.313659)) + \
                      np.arctan(temp + humidity) - np.arctan(humidity - 1.676331) + \
                      0.00391838 * np.power(humidity, 1.5) * np.arctan(0.023101 * humidity) - 4.686035
            
            return 0.7 * wet_bulb + 0.3 * temp
        except:
            return np.nan
    
    def calculate_humidex(self, temp, humidity):
        """Humidex - ìºë‚˜ë‹¤ ê¸°ìƒì²­ ê³µì‹ (1965ë…„)"""
        try:
            # ì´ìŠ¬ì  ì˜¨ë„ ê³„ì‚°
            a, b = 17.27, 237.7
            alpha = ((a * temp) / (b + temp)) + np.log(humidity / 100.0)
            dewpoint = (b * alpha) / (a - alpha)
            
            # Humidex ê³„ì‚°
            e = 6.11 * np.exp(5417.753 * ((1/273.16) - (1/(dewpoint + 273.16))))
            h = 0.5555 * (e - 10.0)
            
            return temp + h
        except:
            return np.nan
    
    def calculate_heat_index(self, temp, humidity):
        """Heat Index - ë¯¸êµ­ ê¸°ìƒì²­ ê³µì‹ (1979ë…„)"""
        try:
            T = temp * 9/5 + 32
            RH = humidity
            
            HI = 0.5 * (T + 61.0 + ((T - 68.0) * 1.2) + (RH * 0.094))
            
            if HI >= 80:
                HI = (-42.379 + 2.04901523*T + 10.14333127*RH 
                      - 0.22475541*T*RH - 6.83783e-3*T**2 
                      - 5.481717e-2*RH**2 + 1.22874e-3*T**2*RH 
                      + 8.5282e-4*T*RH**2 - 1.99e-6*T**2*RH**2)
            
            return (HI - 32) * 5/9
        except:
            return np.nan
    
    def calculate_apparent_temp(self, temp, humidity, wind_speed=5.0):
        """ì²´ê°ì˜¨ë„ - í˜¸ì£¼ ê¸°ìƒì²­ ê³µì‹ (1984ë…„)"""
        try:
            e = humidity / 100 * 6.105 * np.exp(17.27 * temp / (237.7 + temp))
            return temp + 0.33 * e - 0.7 * wind_speed - 4.0
        except:
            return np.nan
    
    def calculate_feels_like_temp(self, temp, humidity, wind_speed=5.0):
        """ì²´ê°ì˜¨ë„ - í˜„ëŒ€ì  ë²„ì „ (1990ë…„ëŒ€)"""
        try:
            if temp >= 26.7:
                return self.calculate_heat_index(temp, humidity)
            elif temp <= 10.0 and wind_speed > 4.8:
                return 13.12 + 0.6215*temp - 11.37*(wind_speed**0.16) + 0.3965*temp*(wind_speed**0.16)
            else:
                return temp + 0.3 * (humidity - 60) / 40 - 0.7 * wind_speed / 10
        except:
            return np.nan
    
    def calculate_UTCI_simplified(self, temp, humidity, wind_speed=5.0):
        """UTCI ê°„ì†Œí™” ê·¼ì‚¬ ê³µì‹ (2012ë…„)"""
        try:
            RH = humidity / 100.0
            v = max(wind_speed, 0.5)
            
            utci = temp
            if temp > 9:
                utci += (1.8 * temp - 32.0) * RH * 0.1
            utci -= (37 - temp) / (37 - temp + 68) * (1.76 + 1.4 * v**0.75) * 0.1
            
            return utci
        except:
            return np.nan
    
    def calculate_temp_humidity_composite(self, temp, humidity):
        """ì˜¨ìŠµë„ ë³µí•© ì§€í‘œ - ê¸°ì¡´ ì—°êµ¬ íš¨ê³¼ ì§€í‘œ (2024ë…„)"""
        try:
            return 0.7 * temp + 0.3 * humidity
        except:
            return np.nan
    
    def load_and_calculate_indices(self, location):
        """ë°ì´í„° ë¡œë”© ë° ëª¨ë“  ë¶ˆì¾Œì§€ìˆ˜ ê³„ì‚°"""
        print(f"\n{location} ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        
        # ë°ì´í„° ë¡œë”©
        file_path = self.data_paths[f'{location}_raw']
        df = pd.read_csv(file_path)
        df['datetime'] = pd.to_datetime(df['datetime'])
        
        # ê²°ì¸¡ê°’ì´ ìˆëŠ” í–‰ ì œê±°
        df_clean = df.dropna(subset=['temperature', 'humidity', 'water_level']).copy()
        
        print(f"ì›ë³¸ ë°ì´í„°: {len(df):,}í–‰, ì •ì œ í›„: {len(df_clean):,}í–‰")
        
        # ëª¨ë“  ë¶ˆì¾Œì§€ìˆ˜ ê³„ì‚°
        print("ë¶ˆì¾Œì§€ìˆ˜ ê³„ì‚° ì¤‘...")
        
        df_clean['effective_temperature'] = df_clean.apply(
            lambda row: self.calculate_effective_temperature(row['temperature'], row['humidity']), axis=1)
        
        df_clean['THI'] = df_clean.apply(
            lambda row: self.calculate_THI(row['temperature'], row['humidity']), axis=1)
        
        df_clean['traditional_DI'] = df_clean.apply(
            lambda row: self.calculate_traditional_DI(row['temperature'], row['humidity']), axis=1)
        
        df_clean['WBGT_simple'] = df_clean.apply(
            lambda row: self.calculate_WBGT_simple(row['temperature'], row['humidity']), axis=1)
        
        df_clean['humidex'] = df_clean.apply(
            lambda row: self.calculate_humidex(row['temperature'], row['humidity']), axis=1)
        
        df_clean['heat_index'] = df_clean.apply(
            lambda row: self.calculate_heat_index(row['temperature'], row['humidity']), axis=1)
        
        # í’ì† ê³ ë ¤ ì§€ìˆ˜ë“¤
        wind_speed_col = df_clean['wind_speed'].fillna(5.0)
        
        df_clean['apparent_temp'] = df_clean.apply(
            lambda row: self.calculate_apparent_temp(
                row['temperature'], row['humidity'], row.get('wind_speed', 5.0)), axis=1)
        
        df_clean['feels_like_temp'] = df_clean.apply(
            lambda row: self.calculate_feels_like_temp(
                row['temperature'], row['humidity'], row.get('wind_speed', 5.0)), axis=1)
        
        df_clean['UTCI_simplified'] = df_clean.apply(
            lambda row: self.calculate_UTCI_simplified(
                row['temperature'], row['humidity'], row.get('wind_speed', 5.0)), axis=1)
        
        df_clean['temp_humidity_composite'] = df_clean.apply(
            lambda row: self.calculate_temp_humidity_composite(row['temperature'], row['humidity']), axis=1)
        
        return df_clean
    
    def analyze_correlations_by_era(self, df, location):
        """ì‹œëŒ€ë³„ ë¶ˆì¾Œì§€ìˆ˜ ì„±ëŠ¥ ë¶„ì„"""
        print(f"\n{location} - ì‹œëŒ€ë³„ ë¶ˆì¾Œì§€ìˆ˜ ì„±ëŠ¥ ë¶„ì„")
        print("=" * 50)
        
        correlations = {}
        
        for idx_name, metadata in self.INDEX_METADATA.items():
            if idx_name in df.columns:
                corr = df[idx_name].corr(df['water_level'])
                correlations[idx_name] = {
                    'correlation': corr,
                    'development_year': metadata['development_year'],
                    'complexity_score': metadata['formula_complexity_score'],
                    'era': metadata['era'],
                    'name': metadata['name']
                }
        
        # ê°œë°œì—°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_by_year = sorted(correlations.items(), key=lambda x: x[1]['development_year'])
        
        print(f"{'ì§€ìˆ˜ëª…':<25} {'ê°œë°œì—°ë„':<8} {'ì‹œëŒ€':<20} {'ë³µì¡ë„':<6} {'ìƒê´€ê³„ìˆ˜':<8}")
        print("-" * 80)
        
        for idx_name, data in sorted_by_year:
            print(f"{data['name']:<25} {data['development_year']:<8} {data['era']:<20} "
                  f"{data['complexity_score']:<6} {data['correlation']:<8.4f}")
        
        return correlations
    
    def analyze_complexity_vs_performance(self, correlations, location):
        """ë³µì¡ë„ vs ì„±ëŠ¥ ê´€ê³„ ë¶„ì„"""
        print(f"\n{location} - ë³µì¡ë„ vs ì„±ëŠ¥ ë¶„ì„")
        print("=" * 40)
        
        # ë³µì¡ë„ë³„ ê·¸ë£¹í™”
        complexity_groups = {}
        for idx_name, data in correlations.items():
            complexity = data['complexity_score']
            if complexity not in complexity_groups:
                complexity_groups[complexity] = []
            complexity_groups[complexity].append({
                'name': idx_name,
                'correlation': abs(data['correlation']),  # ì ˆëŒ“ê°’ìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€
                'era': data['era']
            })
        
        print(f"{'ë³µì¡ë„':<8} {'í‰ê·  ì„±ëŠ¥':<10} {'ìµœê³  ì„±ëŠ¥':<10} {'í•´ë‹¹ ì§€ìˆ˜ë“¤'}")
        print("-" * 60)
        
        for complexity in sorted(complexity_groups.keys()):
            group = complexity_groups[complexity]
            avg_perf = np.mean([item['correlation'] for item in group])
            max_perf = np.max([item['correlation'] for item in group])
            indices = [item['name'] for item in group]
            
            print(f"{complexity:<8} {avg_perf:<10.4f} {max_perf:<10.4f} {', '.join(indices)}")
        
        return complexity_groups
    
    def analyze_era_trends(self, correlations, location):
        """ì‹œëŒ€ë³„ ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„"""
        print(f"\n{location} - ì‹œëŒ€ë³„ ì„±ëŠ¥ íŠ¸ë Œë“œ")
        print("=" * 35)
        
        era_groups = {}
        for idx_name, data in correlations.items():
            era = data['era']
            if era not in era_groups:
                era_groups[era] = []
            era_groups[era].append({
                'name': idx_name,
                'correlation': abs(data['correlation']),
                'year': data['development_year']
            })
        
        # ì‹œëŒ€ìˆœ ì •ë ¬ì„ ìœ„í•œ í‚¤
        era_order = ['Early (1920s)', 'Classical (1950s)', 'Modern (1960s-1980s)', 
                     'Contemporary (1990s-2010s)', 'Latest (2020s)']
        
        print(f"{'ì‹œëŒ€':<25} {'í‰ê·  ì„±ëŠ¥':<10} {'ìµœê³  ì„±ëŠ¥':<10} {'ì§€ìˆ˜ ê°œìˆ˜'}")
        print("-" * 60)
        
        for era in era_order:
            if era in era_groups:
                group = era_groups[era]
                avg_perf = np.mean([item['correlation'] for item in group])
                max_perf = np.max([item['correlation'] for item in group])
                count = len(group)
                
                print(f"{era:<25} {avg_perf:<10.4f} {max_perf:<10.4f} {count}")
        
        return era_groups
    
    def save_results(self, location, correlations, complexity_groups, era_groups):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        results = {
            'location': location,
            'timestamp': datetime.now().isoformat(),
            'correlations': correlations,
            'complexity_analysis': complexity_groups,
            'era_analysis': era_groups,
            'metadata': self.INDEX_METADATA
        }
        
        output_file = f"../results/reports/comprehensive_discomfort_analysis_{location}.json"
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        
        return results
    
    def run_comprehensive_analysis(self):
        """ì¢…í•© ë¶„ì„ ì‹¤í–‰"""
        print("ğŸ¯ ë¬´ì‹¬ì²œ ì¢…í•© ë¶ˆì¾Œì§€ìˆ˜ ë¶„ì„ ì‹œì‘")
        print("=" * 60)
        
        locations = ['cheongju', 'gadeok']
        
        for location in locations:
            # ë°ì´í„° ë¡œë”© ë° ë¶ˆì¾Œì§€ìˆ˜ ê³„ì‚°
            df = self.load_and_calculate_indices(location)
            
            # ìƒê´€ê´€ê³„ ë¶„ì„
            correlations = self.analyze_correlations_by_era(df, location)
            
            # ë³µì¡ë„ vs ì„±ëŠ¥ ë¶„ì„
            complexity_groups = self.analyze_complexity_vs_performance(correlations, location)
            
            # ì‹œëŒ€ë³„ íŠ¸ë Œë“œ ë¶„ì„
            era_groups = self.analyze_era_trends(correlations, location)
            
            # ê²°ê³¼ ì €ì¥
            self.results[location] = self.save_results(location, correlations, complexity_groups, era_groups)
        
        return self.results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = ComprehensiveDiscomfortAnalyzer()
    results = analyzer.run_comprehensive_analysis()
    
    print("\nğŸ‰ ì¢…í•© ë¶„ì„ ì™„ë£Œ!")
    print("\nì£¼ìš” ë°œê²¬ì :")
    
    # ì§€ì—­ë³„ ìµœê³  ì„±ëŠ¥ ì§€ìˆ˜ ë¹„êµ
    for location, result in results.items():
        best_corr = max(result['correlations'].items(), key=lambda x: abs(x[1]['correlation']))
        print(f"\n{location.upper()} ìµœê³  ì„±ëŠ¥:")
        print(f"  - {best_corr[1]['name']}: {best_corr[1]['correlation']:.4f}")
        print(f"  - ê°œë°œì—°ë„: {best_corr[1]['development_year']}")
        print(f"  - ë³µì¡ë„: {best_corr[1]['complexity_score']}")

if __name__ == "__main__":
    main() 